{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Infrastructure-as-code set-up using AWS's SDK for Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load libraries\n",
    "import pandas as pd\n",
    "import boto3\n",
    "import json\n",
    "import configparser\n",
    "import sql\n",
    "import s3fs\n",
    "from botocore.exceptions import ClientError"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Param</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DWH_CLUSTER_TYPE</td>\n",
       "      <td>multi-node</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DWH_NUM_NODES</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DWH_NODE_TYPE</td>\n",
       "      <td>dc2.large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DWH_CLUSTER_IDENTIFIER</td>\n",
       "      <td>project-cluster-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DWH_DB</td>\n",
       "      <td>sparkify</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>DWH_DB_USER</td>\n",
       "      <td>projectuser</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>DWH_DB_PASSWORD</td>\n",
       "      <td>PRojectpassword01!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>DWH_PORT</td>\n",
       "      <td>5439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>DWH_IAM_ROLE_NAME</td>\n",
       "      <td>neidhpa-dwh-project</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Param                Value\n",
       "0        DWH_CLUSTER_TYPE           multi-node\n",
       "1           DWH_NUM_NODES                    4\n",
       "2           DWH_NODE_TYPE            dc2.large\n",
       "3  DWH_CLUSTER_IDENTIFIER    project-cluster-1\n",
       "4                  DWH_DB             sparkify\n",
       "5             DWH_DB_USER          projectuser\n",
       "6         DWH_DB_PASSWORD  PRojectpassword01!!\n",
       "7                DWH_PORT                 5439\n",
       "8       DWH_IAM_ROLE_NAME  neidhpa-dwh-project"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load parameters from a local configuration file\n",
    "config = configparser.ConfigParser()\n",
    "config.read_file(open('dwh.cfg'))\n",
    "\n",
    "KEY                    = config.get('AWS','KEY')\n",
    "SECRET                 = config.get('AWS','SECRET')\n",
    "REGION                 = config.get('AWS','REGION')\n",
    "\n",
    "DWH_CLUSTER_TYPE       = config.get(\"DWH\",\"DWH_CLUSTER_TYPE\")\n",
    "DWH_NUM_NODES          = config.get(\"DWH\",\"DWH_NUM_NODES\")\n",
    "DWH_NODE_TYPE          = config.get(\"DWH\",\"DWH_NODE_TYPE\")\n",
    "DWH_CLUSTER_IDENTIFIER = config.get(\"DWH\",\"DWH_CLUSTER_IDENTIFIER\")\n",
    "\n",
    "DWH_DB                 = config.get(\"DWH\",\"DWH_DB\")\n",
    "DWH_DB_USER            = config.get(\"DWH\",\"DWH_DB_USER\")\n",
    "DWH_DB_PASSWORD        = config.get(\"DWH\",\"DWH_DB_PASSWORD\")\n",
    "DWH_PORT               = config.get(\"DWH\",\"DWH_PORT\")\n",
    "\n",
    "DWH_IAM_ROLE_NAME      = config.get(\"DWH\", \"DWH_IAM_ROLE_NAME\")\n",
    "\n",
    "(DWH_DB_USER, DWH_DB_PASSWORD, DWH_DB)\n",
    "\n",
    "pd.DataFrame({\"Param\":\n",
    "                  [\"DWH_CLUSTER_TYPE\", \"DWH_NUM_NODES\",\n",
    "                   \"DWH_NODE_TYPE\", \"DWH_CLUSTER_IDENTIFIER\",\n",
    "                    \"DWH_DB\", \"DWH_DB_USER\", \"DWH_DB_PASSWORD\",\n",
    "                    \"DWH_PORT\", \"DWH_IAM_ROLE_NAME\"],\n",
    "              \"Value\":\n",
    "                  [DWH_CLUSTER_TYPE, DWH_NUM_NODES,\n",
    "                   DWH_NODE_TYPE, DWH_CLUSTER_IDENTIFIER, \n",
    "                   DWH_DB, DWH_DB_USER, DWH_DB_PASSWORD, \n",
    "                   DWH_PORT, DWH_IAM_ROLE_NAME]\n",
    "             })"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AWS Clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create clients for IAM, EC2, S3 and Redshift\n",
    "ec2 = boto3.resource('ec2',\n",
    "                       region_name=REGION,\n",
    "                       aws_access_key_id=KEY,\n",
    "                       aws_secret_access_key=SECRET\n",
    "                    )\n",
    "\n",
    "s3 = boto3.resource('s3',\n",
    "                       region_name=REGION,\n",
    "                       aws_access_key_id=KEY,\n",
    "                       aws_secret_access_key=SECRET\n",
    "                   )\n",
    "\n",
    "iam = boto3.client('iam',aws_access_key_id=KEY,\n",
    "                     aws_secret_access_key=SECRET,\n",
    "                     region_name=REGION\n",
    "                  )\n",
    "\n",
    "redshift = boto3.client('redshift',\n",
    "                       region_name=REGION,\n",
    "                       aws_access_key_id=KEY,\n",
    "                       aws_secret_access_key=SECRET\n",
    "                       )\n",
    "\n",
    "s3_client = boto3.client('s3',\n",
    "                        region_name=REGION,\n",
    "                        aws_access_key_id=KEY,\n",
    "                        aws_secret_access_key=SECRET\n",
    "                        )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Access to bucket aws-glue-assets-302422927713-us-west-2 is denied.\n",
      "Access to bucket neidhpa-airflow is successful.\n",
      "Access to bucket neidhpa-airflow-project is successful.\n",
      "Access to bucket neidhpa-dwh-project is successful.\n",
      "Access to bucket neidhpa-lake-house is successful.\n",
      "Access to bucket neidhpa-lakehouse-project is successful.\n"
     ]
    }
   ],
   "source": [
    "# List all buckets in the account\n",
    "response = s3_client.list_buckets()\n",
    "buckets = response['Buckets']\n",
    "\n",
    "# For each bucket, try to list its objects\n",
    "for bucket in buckets:\n",
    "    bucket_name = bucket['Name']\n",
    "    try:\n",
    "        s3_client.list_objects_v2(Bucket=bucket_name)\n",
    "        print(f'Access to bucket {bucket_name} is successful.')\n",
    "    except ClientError as e:\n",
    "        print(f'Access to bucket {bucket_name} is denied.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neidhpa-dwh-project/log-data\n",
      "neidhpa-dwh-project/log_json_path.json\n",
      "neidhpa-dwh-project/song-data\n"
     ]
    }
   ],
   "source": [
    "# Set the name of the S3 bucket for the project\n",
    "bucket_name = 'neidhpa-dwh-project'\n",
    "\n",
    "fs = s3fs.S3FileSystem(\n",
    "    key=KEY, \n",
    "    secret=SECRET,\n",
    "    client_kwargs={'region_name': REGION}\n",
    ")\n",
    "\n",
    "# Use the 'fs' object to interact with your S3 bucket.\n",
    "# For instance, to list all files in a bucket:\n",
    "\n",
    "files = fs.ls(f'{bucket_name}/')\n",
    "\n",
    "for file in files:\n",
    "    print(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to combine all JSONs in a given prefix into a single dataframe\n",
    "def jsons_to_df(bucket_name: str, prefix: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Converts all of the JSONs within a given prefix into a single Pandas dataframe.\n",
    "\n",
    "    Args:\n",
    "        bucket_name (str): The name of the S3 bucket.\n",
    "        prefix (str): The prefix in the S3 bucket to get the JSON files from.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A dataframe containing the data from all the JSON files in the given prefix.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialize s3fs object\n",
    "    fs = s3fs.S3FileSystem(\n",
    "        key=KEY,\n",
    "        secret=SECRET,\n",
    "        client_kwargs={'region_name': REGION})\n",
    "\n",
    "    # Initialize a list to hold all dataframes\n",
    "    dfs = []\n",
    "\n",
    "    # Walk through the directories and files in the prefix\n",
    "    for root, dirs, files in fs.walk(f'{bucket_name}/{prefix}'):\n",
    "        for file in files:\n",
    "            # Create the full file path\n",
    "            file_path = f\"{root}/{file}\"\n",
    "\n",
    "            # Open the file and load it into a pandas dataframe\n",
    "            with fs.open(file_path, 'r') as f:\n",
    "                df = pd.read_json(f, lines=True)\n",
    "\n",
    "            # Append the dataframe to the list\n",
    "            dfs.append(df)\n",
    "\n",
    "    # Concatenate all the dataframes in the list into a single dataframe\n",
    "    final_df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe for the log data\n",
    "log_df = jsons_to_df(bucket_name, 'log-data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>auth</th>\n",
       "      <th>firstName</th>\n",
       "      <th>gender</th>\n",
       "      <th>itemInSession</th>\n",
       "      <th>lastName</th>\n",
       "      <th>length</th>\n",
       "      <th>level</th>\n",
       "      <th>location</th>\n",
       "      <th>method</th>\n",
       "      <th>page</th>\n",
       "      <th>registration</th>\n",
       "      <th>sessionId</th>\n",
       "      <th>song</th>\n",
       "      <th>status</th>\n",
       "      <th>ts</th>\n",
       "      <th>userAgent</th>\n",
       "      <th>userId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>Logged In</td>\n",
       "      <td>Walter</td>\n",
       "      <td>M</td>\n",
       "      <td>0</td>\n",
       "      <td>Frye</td>\n",
       "      <td>NaN</td>\n",
       "      <td>free</td>\n",
       "      <td>San Francisco-Oakland-Hayward, CA</td>\n",
       "      <td>GET</td>\n",
       "      <td>Home</td>\n",
       "      <td>1.540919e+12</td>\n",
       "      <td>38</td>\n",
       "      <td>None</td>\n",
       "      <td>200</td>\n",
       "      <td>1541105830796</td>\n",
       "      <td>\"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_4...</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>None</td>\n",
       "      <td>Logged In</td>\n",
       "      <td>Kaylee</td>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "      <td>Summers</td>\n",
       "      <td>NaN</td>\n",
       "      <td>free</td>\n",
       "      <td>Phoenix-Mesa-Scottsdale, AZ</td>\n",
       "      <td>GET</td>\n",
       "      <td>Home</td>\n",
       "      <td>1.540345e+12</td>\n",
       "      <td>139</td>\n",
       "      <td>None</td>\n",
       "      <td>200</td>\n",
       "      <td>1541106106796</td>\n",
       "      <td>\"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebK...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Des'ree</td>\n",
       "      <td>Logged In</td>\n",
       "      <td>Kaylee</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>Summers</td>\n",
       "      <td>246.30812</td>\n",
       "      <td>free</td>\n",
       "      <td>Phoenix-Mesa-Scottsdale, AZ</td>\n",
       "      <td>PUT</td>\n",
       "      <td>NextSong</td>\n",
       "      <td>1.540345e+12</td>\n",
       "      <td>139</td>\n",
       "      <td>You Gotta Be</td>\n",
       "      <td>200</td>\n",
       "      <td>1541106106796</td>\n",
       "      <td>\"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebK...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    artist       auth firstName gender  itemInSession lastName     length  \\\n",
       "0     None  Logged In    Walter      M              0     Frye        NaN   \n",
       "1     None  Logged In    Kaylee      F              0  Summers        NaN   \n",
       "2  Des'ree  Logged In    Kaylee      F              1  Summers  246.30812   \n",
       "\n",
       "  level                           location method      page  registration  \\\n",
       "0  free  San Francisco-Oakland-Hayward, CA    GET      Home  1.540919e+12   \n",
       "1  free        Phoenix-Mesa-Scottsdale, AZ    GET      Home  1.540345e+12   \n",
       "2  free        Phoenix-Mesa-Scottsdale, AZ    PUT  NextSong  1.540345e+12   \n",
       "\n",
       "   sessionId          song  status             ts  \\\n",
       "0         38          None     200  1541105830796   \n",
       "1        139          None     200  1541106106796   \n",
       "2        139  You Gotta Be     200  1541106106796   \n",
       "\n",
       "                                           userAgent userId  \n",
       "0  \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_4...     39  \n",
       "1  \"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebK...      8  \n",
       "2  \"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebK...      8  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show the first 3 rows of the dataframe\n",
    "log_df.head(n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8056 entries, 0 to 8055\n",
      "Data columns (total 18 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   artist         6820 non-null   object \n",
      " 1   auth           8056 non-null   object \n",
      " 2   firstName      7770 non-null   object \n",
      " 3   gender         7770 non-null   object \n",
      " 4   itemInSession  8056 non-null   int64  \n",
      " 5   lastName       7770 non-null   object \n",
      " 6   length         6820 non-null   float64\n",
      " 7   level          8056 non-null   object \n",
      " 8   location       7770 non-null   object \n",
      " 9   method         8056 non-null   object \n",
      " 10  page           8056 non-null   object \n",
      " 11  registration   7770 non-null   float64\n",
      " 12  sessionId      8056 non-null   int64  \n",
      " 13  song           6820 non-null   object \n",
      " 14  status         8056 non-null   int64  \n",
      " 15  ts             8056 non-null   int64  \n",
      " 16  userAgent      7770 non-null   object \n",
      " 17  userId         8056 non-null   object \n",
      "dtypes: float64(2), int64(4), object(12)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "# Show the shape and datatypes of the dataframe\n",
    "log_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_json_files(bucket_name: str, prefix: str) -> int:\n",
    "    \"\"\"\n",
    "    Counts the number of JSON files within a given prefix in an S3 bucket.\n",
    "\n",
    "    Args:\n",
    "        bucket_name (str): The name of the S3 bucket.\n",
    "        prefix (str): The prefix in the S3 bucket to count the JSON files in.\n",
    "        key (str): The AWS access key ID.\n",
    "        secret (str): The AWS secret access key.\n",
    "\n",
    "    Returns:\n",
    "        int: The number of JSON files in the given prefix.\n",
    "    \"\"\"\n",
    "    # Initialize s3fs object\n",
    "    fs = s3fs.S3FileSystem(\n",
    "        key=KEY,\n",
    "        secret=SECRET,\n",
    "        client_kwargs={'region_name': REGION})\n",
    "\n",
    "    # Initialize a counter\n",
    "    count = 0\n",
    "\n",
    "    # Walk through the directories and files in the prefix\n",
    "    for root, dirs, files in fs.walk(f'{bucket_name}/{prefix}'):\n",
    "        for file in files:\n",
    "            # Check if the file is a JSON file\n",
    "            if file.lower().endswith('.json'):\n",
    "                count += 1\n",
    "\n",
    "    return count"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The data are JSON files stored within the *song-data* bucket\n",
    "- Within this bucket there are 8 subfolders labelled alphabetically A-H, each of these subfolders has 26 subfolders labelled alphabetically A-Z, and each of these subfolders has 26 subfolders labeled alphabetically A-Z.\n",
    "- Each individual JSON file is stored within one of the lowest level subfolders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 24 JSON files in the prefix song-data/A/A/A\n"
     ]
    }
   ],
   "source": [
    "lowest_prefix = 'song-data/A/A/A'\n",
    "num_json_files = count_json_files(bucket_name=bucket_name, prefix=lowest_prefix)\n",
    "print(f\"There are {num_json_files} JSON files in the prefix {lowest_prefix}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe for the a subset of the song data\n",
    "example_songs_df = jsons_to_df(bucket_name, lowest_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>song_id</th>\n",
       "      <th>num_songs</th>\n",
       "      <th>title</th>\n",
       "      <th>artist_name</th>\n",
       "      <th>artist_latitude</th>\n",
       "      <th>year</th>\n",
       "      <th>duration</th>\n",
       "      <th>artist_id</th>\n",
       "      <th>artist_longitude</th>\n",
       "      <th>artist_location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SOBLFFE12AF72AA5BA</td>\n",
       "      <td>1</td>\n",
       "      <td>Scream</td>\n",
       "      <td>Adelitas Way</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2009</td>\n",
       "      <td>213.94240</td>\n",
       "      <td>ARJNIUY12298900C91</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SOQPWCR12A6D4FB2A3</td>\n",
       "      <td>1</td>\n",
       "      <td>A Poor Recipe For Civic Cohesion</td>\n",
       "      <td>Western Addiction</td>\n",
       "      <td>37.77916</td>\n",
       "      <td>2005</td>\n",
       "      <td>118.07302</td>\n",
       "      <td>AR73AIO1187B9AD57B</td>\n",
       "      <td>-122.42005</td>\n",
       "      <td>San Francisco, CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SOCIWDW12A8C13D406</td>\n",
       "      <td>1</td>\n",
       "      <td>Soul Deep</td>\n",
       "      <td>The Box Tops</td>\n",
       "      <td>35.14968</td>\n",
       "      <td>1969</td>\n",
       "      <td>148.03546</td>\n",
       "      <td>ARMJAGH1187FB546F3</td>\n",
       "      <td>-90.04892</td>\n",
       "      <td>Memphis, TN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              song_id  num_songs                             title  \\\n",
       "0  SOBLFFE12AF72AA5BA          1                            Scream   \n",
       "1  SOQPWCR12A6D4FB2A3          1  A Poor Recipe For Civic Cohesion   \n",
       "2  SOCIWDW12A8C13D406          1                         Soul Deep   \n",
       "\n",
       "         artist_name  artist_latitude  year   duration           artist_id  \\\n",
       "0       Adelitas Way              NaN  2009  213.94240  ARJNIUY12298900C91   \n",
       "1  Western Addiction         37.77916  2005  118.07302  AR73AIO1187B9AD57B   \n",
       "2       The Box Tops         35.14968  1969  148.03546  ARMJAGH1187FB546F3   \n",
       "\n",
       "   artist_longitude    artist_location  \n",
       "0               NaN                     \n",
       "1        -122.42005  San Francisco, CA  \n",
       "2         -90.04892        Memphis, TN  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show the first 3 rows of the dataframe\n",
    "example_songs_df.head(n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 24 entries, 0 to 23\n",
      "Data columns (total 10 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   song_id           24 non-null     object \n",
      " 1   num_songs         24 non-null     int64  \n",
      " 2   title             24 non-null     object \n",
      " 3   artist_name       24 non-null     object \n",
      " 4   artist_latitude   12 non-null     float64\n",
      " 5   year              24 non-null     int64  \n",
      " 6   duration          24 non-null     float64\n",
      " 7   artist_id         24 non-null     object \n",
      " 8   artist_longitude  12 non-null     float64\n",
      " 9   artist_location   24 non-null     object \n",
      "dtypes: float64(3), int64(2), object(5)\n",
      "memory usage: 2.0+ KB\n"
     ]
    }
   ],
   "source": [
    "# Show the shape and datatypes of the dataframe\n",
    "example_songs_df.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IAM Role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1 Creating a new IAM Role\n",
      "1.2 Attaching Policy\n",
      "1.3 Get the IAM role ARN\n",
      "arn:aws:iam::302422927713:role/neidhpa-dwh-project\n"
     ]
    }
   ],
   "source": [
    "#1.1 Create the role, \n",
    "try:\n",
    "    print(\"1.1 Creating a new IAM Role\") \n",
    "    dwhRole = iam.create_role(\n",
    "        Path='/',\n",
    "        RoleName=DWH_IAM_ROLE_NAME,\n",
    "        Description = \"Allows Redshift clusters to call AWS services on your behalf.\",\n",
    "        AssumeRolePolicyDocument=json.dumps(\n",
    "            {'Statement': [{'Action': 'sts:AssumeRole',\n",
    "               'Effect': 'Allow',\n",
    "               'Principal': {'Service': 'redshift.amazonaws.com'}}],\n",
    "             'Version': '2012-10-17'})\n",
    "    )    \n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    \n",
    "    \n",
    "print(\"1.2 Attaching Policy\")\n",
    "\n",
    "iam.attach_role_policy(RoleName=DWH_IAM_ROLE_NAME,\n",
    "                       PolicyArn=\"arn:aws:iam::aws:policy/AmazonS3ReadOnlyAccess\"\n",
    "                      )['ResponseMetadata']['HTTPStatusCode']\n",
    "\n",
    "iam.attach_role_policy(RoleName=DWH_IAM_ROLE_NAME,\n",
    "                       PolicyArn=\"arn:aws:iam::aws:policy/AmazonRedshiftFullAccess\"\n",
    "                      )['ResponseMetadata']['HTTPStatusCode']\n",
    "\n",
    "print(\"1.3 Get the IAM role ARN\")\n",
    "roleArn = iam.get_role(RoleName=DWH_IAM_ROLE_NAME)['Role']['Arn']\n",
    "\n",
    "print(roleArn)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Redshift cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster created successfully!\n",
      "DWH_ENDPOINT: project-cluster-1.cavkzsgzmk8j.us-west-2.redshift.amazonaws.com\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    response = redshift.create_cluster(        \n",
    "        #HW\n",
    "        ClusterType=DWH_CLUSTER_TYPE,\n",
    "        NodeType=DWH_NODE_TYPE,\n",
    "        NumberOfNodes=int(DWH_NUM_NODES),\n",
    "\n",
    "        #Identifiers & Credentials\n",
    "        DBName=DWH_DB,\n",
    "        ClusterIdentifier=DWH_CLUSTER_IDENTIFIER,\n",
    "        MasterUsername=DWH_DB_USER,\n",
    "        MasterUserPassword=DWH_DB_PASSWORD,\n",
    "        \n",
    "        #Roles (for s3 access)\n",
    "        IamRoles=[roleArn]  \n",
    "    )\n",
    "\n",
    "    # Wait for cluster creation to complete\n",
    "    redshift.get_waiter('cluster_available').\\\n",
    "        wait(ClusterIdentifier=DWH_CLUSTER_IDENTIFIER)\n",
    "    \n",
    "    # Retrieve the endpoint of the cluster\n",
    "    cluster_props = redshift.\\\n",
    "        describe_clusters(ClusterIdentifier=DWH_CLUSTER_IDENTIFIER)['Clusters'][0]\n",
    "    DWH_ENDPOINT = cluster_props['Endpoint']['Address']\n",
    "    \n",
    "    print(\"Cluster created successfully!\")\n",
    "    print(\"DWH_ENDPOINT:\", DWH_ENDPOINT)\n",
    "\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Key</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ClusterIdentifier</td>\n",
       "      <td>project-cluster-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NodeType</td>\n",
       "      <td>dc2.large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ClusterStatus</td>\n",
       "      <td>available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MasterUsername</td>\n",
       "      <td>projectuser</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DBName</td>\n",
       "      <td>sparkify</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Endpoint</td>\n",
       "      <td>{'Address': 'project-cluster-1.cavkzsgzmk8j.us-west-2.redshift.amazonaws.com', 'Port': 5439}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>VpcId</td>\n",
       "      <td>vpc-0478d8d5f8fd4539b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NumberOfNodes</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Key  \\\n",
       "0  ClusterIdentifier   \n",
       "1           NodeType   \n",
       "2      ClusterStatus   \n",
       "3     MasterUsername   \n",
       "4             DBName   \n",
       "5           Endpoint   \n",
       "6              VpcId   \n",
       "7      NumberOfNodes   \n",
       "\n",
       "                                                                                          Value  \n",
       "0                                                                             project-cluster-1  \n",
       "1                                                                                     dc2.large  \n",
       "2                                                                                     available  \n",
       "3                                                                                   projectuser  \n",
       "4                                                                                      sparkify  \n",
       "5  {'Address': 'project-cluster-1.cavkzsgzmk8j.us-west-2.redshift.amazonaws.com', 'Port': 5439}  \n",
       "6                                                                         vpc-0478d8d5f8fd4539b  \n",
       "7                                                                                             4  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function to neatly display select properties of the Redshift cluster\n",
    "def RedshiftProps(props):\n",
    "    # Set the maximum width of a column to display the entire content of a cell\n",
    "    pd.set_option('display.max_colwidth', None)\n",
    "    \n",
    "    # List of keys (properties) to display\n",
    "    keysToShow = [\"ClusterIdentifier\", \"NodeType\", \"ClusterStatus\",\n",
    "                \"MasterUsername\", \"DBName\", \"Endpoint\",\n",
    "                \"NumberOfNodes\", 'VpcId']\n",
    "    \n",
    "    # Create a list of tuples where each tuple is (key, value)\n",
    "    # Include only the keys that are present in keysToShow list\n",
    "    x = [(k, v) for k,v in props.items() if k in keysToShow]\n",
    "    \n",
    "    # Create and return a dataframe from the list of tuples\n",
    "    # with column names as \"Key\" and \"Value\"\n",
    "    return pd.DataFrame(data=x, columns=[\"Key\", \"Value\"])\n",
    "\n",
    "# Get the properties of the Redshift cluster\n",
    "# This method returns a response object from which we extract the cluster details\n",
    "# For this project, we assume there's only one cluster and we access this by index [0]\n",
    "myClusterProps = redshift.describe_clusters(ClusterIdentifier=DWH_CLUSTER_IDENTIFIER)['Clusters'][0]\n",
    "\n",
    "# Call the RedshiftProps function defined above to display select properties of the cluster\n",
    "RedshiftProps(myClusterProps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DWH_ENDPOINT ::  project-cluster-1.cavkzsgzmk8j.us-west-2.redshift.amazonaws.com\n",
      "DWH_ROLE_ARN ::  arn:aws:iam::302422927713:role/neidhpa-dwh-project\n"
     ]
    }
   ],
   "source": [
    "# Get the cluster endpoint and role ARN from the properties\n",
    "DWH_ENDPOINT = myClusterProps['Endpoint']['Address']\n",
    "DWH_ROLE_ARN = myClusterProps['IamRoles'][0]['IamRoleArn']\n",
    "# Print the values\n",
    "print(\"DWH_ENDPOINT :: \", DWH_ENDPOINT)\n",
    "print(\"DWH_ROLE_ARN :: \", DWH_ROLE_ARN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ec2.SecurityGroup(id='sg-05ad93b78bd502d9e')\n",
      "Existing rules:\n",
      "{'FromPort': 5439, 'IpProtocol': 'tcp', 'IpRanges': [{'CidrIp': '0.0.0.0/0', 'Description': 'Allow traffic from anywhere in the world'}], 'Ipv6Ranges': [], 'PrefixListIds': [], 'ToPort': 5439, 'UserIdGroupPairs': []}\n",
      "Rule already exists\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # Use the VPC ID property of the Redshift cluster to get the VPC\n",
    "    vpc = ec2.Vpc(id=myClusterProps['VpcId'])\n",
    "    \n",
    "    # From all the security groups associated with this VPC, get the first one.\n",
    "    # This assumes the first security group is the default one.\n",
    "    defaultSg = list(vpc.security_groups.all())[0]\n",
    "    print(defaultSg)\n",
    "    \n",
    "    # Get the existing inbound (ingress) rules for this security group\n",
    "    existing_rules = defaultSg.ip_permissions\n",
    "    print(\"Existing rules:\")\n",
    "    \n",
    "    # Check each existing rule to see if the rule we want to add already exists\n",
    "    for rule in existing_rules:\n",
    "        print(rule)\n",
    "        # The rule we want to add is for inbound TCP traffic on a certain port (DWH_PORT),\n",
    "        # allowing any IP to connect (0.0.0.0/0)\n",
    "        if (\n",
    "            rule['IpProtocol'].lower() == 'tcp' and\n",
    "            rule['FromPort'] == int(DWH_PORT) and\n",
    "            rule['ToPort'] == int(DWH_PORT) and\n",
    "            any(x['CidrIp'] == '0.0.0.0/0' for x in rule['IpRanges'])\n",
    "        ):\n",
    "            print(\"Rule already exists\")\n",
    "            break\n",
    "    else:\n",
    "        # If the loop doesn't break, the rule does not exist and we the rule\n",
    "        defaultSg.authorize_ingress(\n",
    "            GroupName=defaultSg.group_name,\n",
    "            CidrIp='0.0.0.0/0',\n",
    "            IpProtocol='TCP',\n",
    "            FromPort=int(DWH_PORT),\n",
    "            ToPort=int(DWH_PORT)\n",
    "        )\n",
    "        \n",
    "# If there's an error (e.g. permissions error when trying to modify security group)\n",
    "# print the error message.\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the SQL extension\n",
    "%load_ext sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "postgresql://projectuser:PRojectpassword01!!@project-cluster-1.cavkzsgzmk8j.us-west-2.redshift.amazonaws.com:5439/sparkify\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Connected: projectuser@sparkify'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Confirm the connection to the Redshift cluster\n",
    "conn_string=\"postgresql://{}:{}@{}:{}/{}\".\\\n",
    "    format(DWH_DB_USER, DWH_DB_PASSWORD, DWH_ENDPOINT, DWH_PORT,DWH_DB)\n",
    "print(conn_string)\n",
    "%sql $conn_string"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "udacity",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
